{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Lab 3\n",
    "### Neural Networks\n",
    "\n",
    "In the following exercise class we explore how to design and train neural networks in various ways.\n",
    "\n",
    "#### Prerequisites:\n",
    "\n",
    "In order to follow the exercises you need to:\n",
    "1. Activate your conda environment from last week via: `source activate <env-name>` \n",
    "2. Install tensorflow (https://www.tensorflow.org) via: `pip install tensorflow` (CPU-only)\n",
    "3. Install keras (provides high level wrapper for tensorflow) (https://keras.io) via: `pip install keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Create a 2 layer network that acts as an XOR gate using numpy.\n",
    "\n",
    "XOR is a fundamental logic gate that outputs a one whenever there is an odd parity of ones in its input and zero otherwise. For two inputs this can be thought of as an exclusive or operation and the associated boolean function is fully characterized by the following truth table.\n",
    "\n",
    "| X | Y | XOR(X,Y) |\n",
    "|---|---|----------|\n",
    "| 0 | 0 |    0     |\n",
    "| 0 | 1 |    1     |\n",
    "| 1 | 0 |    1     |\n",
    "| 1 | 1 |    0     |\n",
    "\n",
    "The function of an XOR gate can also be understood as a classification problem on $v \\in \\{0,1\\}^2$ and we can think about designing a classifier acting as an XOR gate. It turns out that this problem is not solvable by any single layer perceptron (https://en.wikipedia.org/wiki/Perceptron) because the set of points $\\{(0,0), (0,1), (1,0), (1,1)\\}$ is not linearly seperable.\n",
    "\n",
    "**Design a two layer perceptron using basic numpy matrix operations that implements an XOR Gate on two inputs. Think about the flow of information and accordingly set the weight values by hand.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([(0, 0), (0, 1), (1, 0), (1, 1)], [0, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_xor_data():\n",
    "    X = [(i,j) for i in [0,1] for j in [0,1]]\n",
    "    y = [int(np.logical_xor(x[0], x[1])) for x in X]\n",
    "    return X, y\n",
    "    \n",
    "print(generate_xor_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints\n",
    "A single layer in a multilayer perceptron can be described by the equation $y = f(\\vec{b} + W\\vec{x})$ with $f$ the logistic function, a smooth and differentiable version of the step function, and defined as $f(z) = \\frac{1}{1+e^{-z}}$. $\\vec{b}$ is the so called bias, a constant offset vector and $W$ is the weight matrix. However, since we set the weights by hand feel free to use hard thresholding instead of using the logistic function. Write down the equation for a two layer MLP and implement it with numpy. For documentation see https://docs.scipy.org/doc/numpy-1.13.0/reference/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nImplement your solution here.\\n'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implement your solution here.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| X | Y | AND(NOT X, Y) | AND(X,NOT Y) | OR[AND(NOT X, Y), AND(X, NOT Y)]| XOR(X,Y) |\n",
    "|---|---|---------------|--------------|---------------------------------|----------|\n",
    "| 0 | 0 |    0          |      0       |                 0               |    0     |\n",
    "| 0 | 1 |    1          |      0       |                 1               |    1     |\n",
    "| 1 | 0 |    0          |      1       |                 1               |    1     |\n",
    "| 1 | 1 |    0          |      0       |                 0               |    0     |\n",
    "\n",
    "Implement XOR as a combination of 2 AND Gates and 1 OR gate where each neuron in the network acts as one of these gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Output XOR\n",
      "(0, 0) 0    0\n",
      "(0, 1) 1    1\n",
      "(1, 0) 1    1\n",
      "(1, 1) 0    0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Definitions:\n",
    "\n",
    "Input = np.array([X,Y])\n",
    "\n",
    "0 if value < 0.5\n",
    "1 if value >= 0.5\n",
    "\"\"\"\n",
    "\n",
    "def threshold(vector):\n",
    "    return (vector>=0.5).astype(float)\n",
    "\n",
    "def mlp(x, W0, W1, b0, b1, f):\n",
    "    x0 = f(np.dot(W0, x) + b0)\n",
    "    x1 = f(np.dot(W1, x0) + b1)\n",
    "    return x1\n",
    "\n",
    "# AND(NOT X, Y)\n",
    "w_andnotxy = np.array([-1.0, 1.0])\n",
    "# AND(X, NOT Y)\n",
    "w_andxnoty = np.array([1.0, -1.0])\n",
    "# W0 weight matrix:\n",
    "W0 = np.vstack([w_andnotxy, w_andxnoty])\n",
    "\n",
    "# OR(X,Y)\n",
    "w_or = np.array([1., 1.])\n",
    "W1 = w_or\n",
    "\n",
    "# No biases needed\n",
    "b0 = np.array([0.0,0.0])\n",
    "b1 = 0.0\n",
    "\n",
    "print(\"Input\", \"Output\", \"XOR\")\n",
    "xx,yy = generate_xor_data()\n",
    "for x,y in zip(xx, yy):\n",
    "    print(x, int(mlp(x, W0, W1, b0, b1, threshold)),\"  \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
