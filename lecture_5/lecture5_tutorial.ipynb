{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import scipy.sparse.linalg\n",
    "import scipy.stats\n",
    "from scipy.ndimage.filters import gaussian_filter1d,gaussian_filter\n",
    "from six.moves import urllib\n",
    "import os\n",
    "import sklearn.decomposition\n",
    "from PIL import Image\n",
    "\n",
    "# before we start install UMAP\n",
    "# (see documentation here https://github.com/lmcinnes/umap)\n",
    "# pip install umap-learn\n",
    "\n",
    "# download image set from UPenn\n",
    "if not os.path.isfile('image_data/img1.jpg'):\n",
    "    if not os.path.exists('image_data'):\n",
    "        os.mkdir('image_data')\n",
    "    for d in range(66):\n",
    "        with urllib.request.urlopen('ftp://tofu.psych.upenn.edu/fulldb/cd01A/DSC_%04d.JPG'%(d+1)) as response:\n",
    "            with open('image_data/img%d.jpg'%d,'wb') as f:\n",
    "                f.write(response.read())\n",
    "\n",
    "# download 2-photon data\n",
    "if not os.path.isfile('data/stimspont.npy'):\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "    with urllib.request.urlopen('http://www.gatsby.ucl.ac.uk/~cstringer/stimspont.npy') as response:\n",
    "        with open('data/stimspont.npy','wb') as f:\n",
    "            f.write(response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract patches from images and make them grayscale!\n",
    "nyp = 35\n",
    "nxp = 35\n",
    "n0 = 250\n",
    "imgs = np.zeros((66*n0,nyp,nxp),dtype=np.uint8)    \n",
    "for d in range(66):\n",
    "    img=np.array(Image.open('image_data/img%d.jpg'%d))\n",
    "    img = np.round((img.astype(np.float32)).mean(axis=2)).astype(np.uint8)\n",
    "    ny,nx = img.shape\n",
    "    for k in range(n0):\n",
    "        ry = np.random.randint(ny-nyp)\n",
    "        rx = np.random.randint(nx-nxp)\n",
    "        py = np.arange(ry,ry+nyp,dtype=int)\n",
    "        px = np.arange(rx,rx+nxp,dtype=int)\n",
    "        imgs[k+d*n0,:,:] = img[np.ix_(py,px)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(12,12))\n",
    "for n in range(100):\n",
    "    ax = fig.add_subplot(10,10,n+1)\n",
    "    ax.imshow(imgs[np.random.randint(imgs.shape[0]),:,:], cmap=plt.get_cmap('gray'))\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find the principal components of the image patches\n",
    "\n",
    "# first flatten the images\n",
    "imgflat = np.reshape(imgs,(imgs.shape[0],-1))\n",
    "\n",
    "# remember scipy.sparse.linalg.eigsh? we'll need a covariance matrix for that\n",
    "# compute covariance of images\n",
    "imgcov = (imgflat-imgflat.mean(axis=1)[:,np.newaxis]).T @ (imgflat-imgflat.mean(axis=1)[:,np.newaxis])\n",
    "\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "plt.imshow(imgcov)\n",
    "plt.title('covariance is a circulant matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### compute eigenvectors\n",
    "#npcs = 100\n",
    "#sv,u = scipy.sparse.linalg.eigsh(imgcov, k=npcs)\n",
    "\n",
    "# they're in reverse order (u[:,-1] is top PC)\n",
    "\n",
    "# visualize the PCs\n",
    "fig=plt.figure(figsize=(12,12))\n",
    "for n in range(npcs):\n",
    "    ax = fig.add_subplot(10,10,n+1)\n",
    "    ax.imshow(np.reshape(u[:,-(n+1)],(nyp,nxp)), cmap=plt.get_cmap('gray'))\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find the independent components! (ICA)\n",
    "# model = sklearn.decomposition.FastICA(n_components=100,algorithm='parallel')\n",
    "# flattened and mean-centered data\n",
    "# model = model.fit(imgflat - imgflat.mean(axis=1)[:,np.newaxis])\n",
    "# s = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the ICs\n",
    "fig=plt.figure(figsize=(12,12))\n",
    "for n in range(100):\n",
    "    ax = fig.add_subplot(10,10,n+1)\n",
    "    ax.imshow(np.reshape(s[n,:],(nyp,nxp)), cmap=plt.get_cmap('gray'))\n",
    "    ax.axis('off')\n",
    "    #ax.set_title('IC %d'%(n+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try UMAP or TSNE, look up parameters and play with them\n",
    "# may need to increase number of iterations\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "\n",
    "# use smaller image patches (and fewer)\n",
    "nyp = 15\n",
    "nxp = 15\n",
    "n0 = 100\n",
    "imgs = np.zeros((66*n0,nyp,nxp),dtype=np.uint8)    \n",
    "for d in range(66):\n",
    "    img=np.array(Image.open('image_data/img%d.jpg'%d))\n",
    "    img = np.round((img.astype(np.float32)).mean(axis=2)).astype(np.uint8)\n",
    "    ny,nx = img.shape\n",
    "    for k in range(n0):\n",
    "        ry = np.random.randint(ny-nyp)\n",
    "        rx = np.random.randint(nx-nxp)\n",
    "        py = np.arange(ry,ry+nyp,dtype=int)\n",
    "        px = np.arange(rx,rx+nxp,dtype=int)\n",
    "        imgs[k+d*n0,:,:] = img[np.ix_(py,px)]\n",
    "        \n",
    "imgflat = np.reshape(imgs,(imgs.shape[0],-1)).astype(np.float32)\n",
    "imgflat -= imgflat.mean(axis=1)[:,np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run UMAP and/or TSNE\n",
    "# UMAP\n",
    "import umap\n",
    "# model = umap.UMAP(n_neighbors=40,n_components=2,min_dist=0.05)\n",
    "\n",
    "# TSNE\n",
    "# mode = TSNE(n_components=2,perplexity=50)\n",
    "\n",
    "### if you want you can download and install the multicore version of tsne\n",
    "# (https://github.com/DmitryUlyanov/Multicore-TSNE)\n",
    "# from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "# tsne = TSNE(n_jobs=8)\n",
    "# out  = tsne.fit_transform(imgflat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(plt)\n",
    "%matplotlib notebook\n",
    "\n",
    "# create figure and plot scatter\n",
    "\n",
    "# create the annotations box\n",
    "#im = OffsetImage(img0[0,:,:])\n",
    "fig, axes = plt.subplots(5,10, figsize=(9,5))\n",
    "for ni in range(5):\n",
    "    for nj in range(10):\n",
    "        axes[ni,nj].axis('off')\n",
    "\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.plot(out[:,0],out[:,1], ls=\"\", marker=\".\")\n",
    "    \n",
    "def onclick(event):\n",
    "    # if the mouse is over the scatter points\n",
    "    #if line.contains(event)[0]:\n",
    "    # find out the index within the array from the event\n",
    "    dists = (out[:,0]-event.xdata)**2 + (out[:,1]-event.ydata)**2\n",
    "    inds = dists.argsort()[:25]\n",
    "    for ni in range(5):\n",
    "        for nj in range(5):\n",
    "            axes[ni,nj+5].imshow(imgs[inds[ni+nj*5],:,:],plt.get_cmap('gray'))\n",
    "            axes[ni,nj+5].axis('off')\n",
    "    plt.show()\n",
    "    #fig.canvas.draw_idle()\n",
    "\n",
    "# add callback for mouse moves\n",
    "fig.canvas.mpl_connect('button_press_event', onclick)           \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's decompose the neural responses!\n",
    "\n",
    "# load downloaded data\n",
    "dat = np.load('data/stimspont.npy')\n",
    "dat = dat.item()\n",
    "resp  = dat['resp'] # stimulus responses x neurons\n",
    "istim  = dat['istim'] # identity of stimulus (0-31)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run some TSNE here!!\n",
    "# and/or other dimensionality reductions\n",
    "#out = TSNE...\n",
    "# can also try umap if pip installed\n",
    "# model = umap.UMAP(n_neighbors=15, min_dist=0.05,n_components=2) # can use many components!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### alternatively, try PCA (it shouldn't look good)\n",
    "#covResp = (resp - resp.mean(axis=1)[:,np.newaxis]) @ (resp - resp.mean(axis=1)[:,np.newaxis]).T\n",
    "#sv,out = scipy.sparse.linalg.eigsh(covResp, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results here\n",
    "%matplotlib inline\n",
    "cmap = cm.get_cmap('gist_ncar')\n",
    "cmap = cmap(np.linspace(0,0.9,32))\n",
    "cmap = cmap[np.random.permutation(32),:]\n",
    "plt.figure(figsize=(6,6))\n",
    "# each point is colored based on stimulus identity\n",
    "plt.scatter(out[:,0],out[:,1],color=cmap[istim,:],marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify results\n",
    "import sklearn.neighbors\n",
    "\n",
    "# classifier\n",
    "n_neighbors = 1\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "# fit classifier using half of the data\n",
    "# low-dimensional data\n",
    "svc = clf.fit(out[::2,:],istim[::2])\n",
    "# predict stimuli from other half\n",
    "istim_pred = clf.predict(out[1::2,:])\n",
    "accuracy   = (istim_pred==istim[1::2]).mean()\n",
    "print(accuracy)\n",
    "\n",
    "# also, train classifier with more dimensions (all data)\n",
    "# does dimensionality reduction help classification?\n",
    "\n",
    "# try other classifiers like an SVM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
